{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-25 22:54:05,303 - pyswarms.single.global_best - INFO - Optimize for 10 iters with {'c1': 0.5, 'c2': 0.3, 'w': 0.9}\n",
      "pyswarms.single.global_best:   0%|          |0/10"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "import pyswarms as ps\n",
    "\n",
    "# Load the dataset\n",
    "df = pd.read_excel(r'D:/paper/qb/data/lab_data.xlsx')\n",
    "df[1:100]\n",
    "X = df.loc[:, ['H', 'S', 'Q', 'D50', 'D84', 'R']].values\n",
    "y = df.loc[:, ['qs']].values\n",
    "\n",
    "# Perform feature scaling\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler1 = MinMaxScaler().fit(X)\n",
    "X1 = scaler1.transform(X)\n",
    "scaler2 = MinMaxScaler().fit(y)\n",
    "y1 = scaler2.transform(y)\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X1, y1, test_size=0.2, random_state=0)\n",
    "y_train = y_train.ravel()\n",
    "y_test = y_test.ravel()\n",
    "\n",
    "# Define the objective function to optimize\n",
    "def optimize_model(particles):\n",
    "    particles = particles.astype(int)\n",
    "\n",
    "    # Define the model architecture\n",
    "    model = Sequential()\n",
    "    model.add(Dense(units=particles[:, 0], activation='relu', input_dim=X.shape[1]))\n",
    "    model.add(Dense(units=particles[:, 1], activation='relu'))\n",
    "    model.add(Dense(units=particles[:, 2], activation='relu'))\n",
    "    model.add(Dense(units=1, activation='linear'))\n",
    "\n",
    "    # Compile the model\n",
    "    from tensorflow.keras.metrics import RootMeanSquaredError\n",
    "    model.compile(loss='mean_squared_error', optimizer='adam', metrics=[RootMeanSquaredError()])\n",
    "\n",
    "    # Train the model\n",
    "    model.fit(X_train, y_train, epochs=10, batch_size=10, verbose=0)\n",
    "\n",
    "    # Evaluate the model\n",
    "    loss = model.evaluate(X_test, y_test, verbose=0)[:, 0]\n",
    "\n",
    "    return loss\n",
    "\n",
    "# Define the bounds for particle values\n",
    "bounds = (np.array([10, 10, 10]), np.array([30, 30, 30]))\n",
    "\n",
    "# Define the PSO optimization function\n",
    "def pso_optimization():\n",
    "    # Define the PSO hyperparameters\n",
    "    num_particles = 5\n",
    "    max_iterations = 10\n",
    "\n",
    "    # Define the options for the optimizer\n",
    "    options = {'c1': 0.5, 'c2': 0.3, 'w': 0.9}\n",
    "\n",
    "    # Initialize the optimizer\n",
    "    optimizer = ps.single.GlobalBestPSO(n_particles=num_particles, dimensions=3, bounds=bounds, options=options)\n",
    "\n",
    "    # Perform optimization\n",
    "    best_cost, best_pos = optimizer.optimize(optimize_model, iters=max_iterations, n_processes=4)\n",
    "\n",
    "    # Print the best cost and particle values\n",
    "    print('Best Cost:', best_cost)\n",
    "    print('Best Particle:', best_pos)\n",
    "\n",
    "# Run the PSO optimization\n",
    "pso_optimization()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
